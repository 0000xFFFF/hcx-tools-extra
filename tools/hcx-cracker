#!/usr/bin/env python3

import os
import re
import argparse
from utils import (
    rslatin_check, rslatin_replace, wordlst2args, 
    load_config_file, get_script_dir, parse_hash_line,
    load_wordlist_set, write_file_with_permissions, read_lines_from_file
)

# Constants
SH_HEADER = "#!/bin/sh -x\n"
DETECT_WORDLISTS_MIN_STRING_LEN = 4
BLACKLIST_FILE = 'hcx-cracker-blacklist.txt'
WORDLIST_FILE = 'hcx-cracker-wordlist.txt'


def load_blacklist():
    """Load blacklist items from config file."""
    config_path = os.path.join(get_script_dir(), BLACKLIST_FILE)
    return set(load_config_file(config_path))


def load_detect_wordlists():
    """Load detect wordlist paths from config file."""
    config_path = os.path.join(get_script_dir(), WORDLIST_FILE)
    return load_config_file(config_path)


def detect_words_in_essid(essid, detect_set):
    """Detect words from detect_set that appear in the ESSID."""
    essid_lower = essid.lower()
    return [word for word in detect_set if word in essid_lower]


def is_blacklisted(essid, blacklist):
    """Check if ESSID matches blacklist criteria."""
    if any(blacklist_item in essid for blacklist_item in blacklist):
        return True
    if len(essid) == 6 and re.fullmatch(r"[0-9a-fA-F]{6}", essid):
        return True
    return False


def extract_before_number(s):
    """Extract substring before first digit."""
    for i, c in enumerate(s):
        if c.isdigit():
            return s[:i]
    return ""


def re_split_essid(word):
    """Split ESSID by various delimiters."""
    return re.split(r"&|'s\s|\s|_|-", word)


def split_camel_case(text):
    """Split camelCase or PascalCase string."""
    return re.split(r'(?<!^)(?=[A-Z])', text)


def generate_word_variations(essid, detect_set=None, use_detect=False):
    """Generate all word variations from an ESSID."""
    wordlst_set = set()
    wordlst = []

    def add_unique(input_word):
        word = input_word.strip()
        if len(word) > 1 and word and word not in wordlst_set:
            wordlst_set.add(word)
            wordlst.append(word)

    def add_variations(word):
        add_unique(word)
        numless_word = re.sub(r'\d', '', word)
        add_unique(numless_word)
        add_unique(extract_before_number(word))

    def add_word_combinations(words):
        for word in words:
            add_variations(word)
        add_variations("".join(words))
        add_variations("".join(reversed(words)))

    # Generate variations
    add_variations(essid)
    add_word_combinations(re_split_essid(essid))
    add_word_combinations(split_camel_case(essid))
    
    if use_detect and detect_set:
        detected_words = detect_words_in_essid(essid, detect_set)
        add_word_combinations(detected_words)

    return wordlst


def essid2wordlst(input_essid, blacklist, detect_set=None, use_blacklist=False, use_detect=False):
    """Generate wordlist variations from an ESSID."""
    essid = input_essid.replace("\"", "")

    if rslatin_check(essid):
        essid = rslatin_replace(essid)

    if use_blacklist and is_blacklisted(essid, blacklist):
        return []

    return generate_word_variations(essid, detect_set, use_detect)


def process_hashes(hashes_lines, args, blacklist, detect_set=None):
    """Process all hash lines and generate wordlists."""
    items = []
    counter = 0
    skipped = 0

    for line in hashes_lines:
        if not line:
            continue

        counter += 1
        parsed = parse_hash_line(line)
        
        if not parsed:
            print(f"Invalid line format: {line}")
            continue

        print(f"{counter}\t{parsed['type']}\t{parsed['hash']}\t{parsed['bssid']}\t{parsed['mac']}\t{parsed['essid']}", end=" --> ")

        if args.auto:
            wordlst = essid2wordlst(
                parsed['essid'], 
                blacklist, 
                detect_set, 
                use_blacklist=args.blacklist, 
                use_detect=args.detect
            )
            if not wordlst:
                skipped += 1
                print(f"BLACKLISTED ({skipped})")
                continue
            print(" ".join(wordlst))
        else:
            wordlst = input(" --> ").split()
            if not wordlst:
                skipped += 1
                print(f"SKIPPED ({skipped})")
                continue

        genlst = wordlst2args(wordlst)
        items.append([
            parsed['line'], 
            parsed['type'], 
            parsed['hash'], 
            parsed['bssid'], 
            parsed['mac'], 
            parsed['essid'], 
            genlst, 
            len(wordlst)
        ])

    return items, skipped


def generate_hash_files(items):
    """Generate individual hash files and return file mappings."""
    items.sort(key=lambda x: (x[7], x[5]))
    
    prev_essid = ""
    prev_file_1 = ""
    prev_file_2 = ""
    files = []
    gen_commands = [SH_HEADER]

    for num, item in enumerate(items, 1):
        file_1 = f"hash{num:03}.txt"
        file_2 = f"hash{num:03}.lst"
        dogen = True

        if prev_essid and prev_essid == item[5]:
            file_1 = prev_file_1
            file_2 = prev_file_2
            with open(file_1, 'a') as f1:
                f1.write(f"{item[0]}\n")
            dogen = False
        else:
            with open(file_1, 'w') as f1:
                f1.write(f"{item[0]}\n")

        if dogen:
            command = f"hcx-fastgenlst -lut123 {item[6]} -o \"{file_2}\" # {item[5]}\n"
            gen_commands.append(command)
            print(f"| {command}", end="")
            files.append([file_1, file_2, item])

        prev_essid = item[5]
        prev_file_1 = file_1
        prev_file_2 = file_2

    write_file_with_permissions("gen.sh", "".join(gen_commands))
    return files


def build_hashcat_command(hashes_filename, wordlist_path, part_num, hash_file=None, session=None, comment=""):
    """Build a hashcat command string."""
    target = hash_file if hash_file else f'"{hashes_filename}"'
    sess = session if session else f'"part{part_num}"'
    cmd = f"hashcat --quiet -m 22000 {target} -a 0 {wordlist_path} -w 4 --session {sess} 2>/dev/null"
    if comment:
        cmd += f" # {comment}"
    return cmd + "\n"


def generate_run_script(files, args):
    """Generate the run.sh script with hashcat commands."""
    print(f"\n+--> run.sh")
    
    run_commands = [SH_HEADER]
    print(f"| {SH_HEADER}", end="")

    # Shortlists
    if args.lists:
        for i in range(1, 14):
            wordlist = f'"/home/user/.vip/lists/wlst/commonfirst/parts/hgl_part{i}.txt"'
            cmd = build_hashcat_command(args.hashes, wordlist, i)
            run_commands.append(cmd)
            print(f"| {cmd}", end="")

    # Generated wordlists
    for file_1, file_2, item in files:
        cmd = build_hashcat_command(
            args.hashes, 
            file_2, 
            None, 
            hash_file=file_1, 
            session=f'"{item[2]}"',
            comment=f"{item[3]} {item[5]}"
        )
        run_commands.append(cmd)
        print(f"| {cmd}", end="")

    # Longlists
    if args.lists:
        for i in range(14, 25):
            wordlist = f'"/home/user/.vip/lists/wlst/commonfirst/parts/hgl_part{i}.txt"'
            cmd = build_hashcat_command(args.hashes, wordlist, i)
            run_commands.append(cmd)
            print(f"| {cmd}", end="")

    write_file_with_permissions("run.sh", "".join(run_commands))


def parse_arguments():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description='Generate hashcat scripts and wordlists from ESSIDs for cracking. '
                    'After running hcx-cracker... Run ./gen.sh to generate wordlists '
                    'and then ./run.sh to start cracking...'
    )
    parser.add_argument('-a', '--auto', action='store_true', 
                        help="Generate wordlst automatically by ESSID alone.")
    parser.add_argument('-b', '--blacklist', action='store_true', 
                        help="Skip hashes that don't generate a decent wordlist using the ESSID")
    parser.add_argument('-d', '--detect', action='store_true', 
                        help="Extends -a option ... detect words in essid from dictionary wordlists")
    parser.add_argument('-l', '--lists', action='store_true', 
                        help="Add wordlists to ./run.sh")
    parser.add_argument('hashes', help="Path to hashes input file")
    return parser.parse_args()


def main():
    """Main execution function."""
    args = parse_arguments()

    # Load configuration
    blacklist = load_blacklist()
    detect_set = None
    
    if args.detect:
        wordlist_paths = load_detect_wordlists()
        detect_set = load_wordlist_set(wordlist_paths, DETECT_WORDLISTS_MIN_STRING_LEN)

    # Read hashes file
    hashes_lines = read_lines_from_file(args.hashes)

    # Process hashes
    items, skipped = process_hashes(hashes_lines, args, blacklist, detect_set)

    # Generate scripts
    print(f"\n+--> gen.sh")
    files = generate_hash_files(items)
    generate_run_script(files, args)

    # Summary
    print()
    print(f" -- files..: {len(files)}")
    print(f" -- skipped: {skipped}")
    print(" -- done.")


if __name__ == "__main__":
    main()

